{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "nBQClrFUQrqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"train_data.csv\")"
      ],
      "metadata": {
        "id": "nEPh3rvdQWxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vx6Z-U6ZOfs-"
      },
      "outputs": [],
      "source": [
        "df[\"remarks\"] = \"\"\n",
        "df[\"remarks\"] = df[\"remarks\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "n-w3UAi5Q4Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: now using NLTK library do sentiment analysis on the column predicted attention values and add remarks to remarks column if the values are greater than 0.7 and less than 1 add remark as high attention if in  the range is 0.4(inclusive)-0.7 add remark as medium attention and less than 0.4 than consider it as low attention\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def analyze_sentiment(value):\n",
        "  if value > 0.7:\n",
        "    return \"High Attention\"\n",
        "  elif value >= 0.4:\n",
        "    return \"Medium Attention\"\n",
        "  else:\n",
        "    return \"Low Attention\"\n",
        "\n",
        "df[\"remarks\"] = df[\"predicted_attention_values\"].apply(lambda x: analyze_sentiment(x))"
      ],
      "metadata": {
        "id": "AOY-o1i3RR5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: do the same on predicted_attention_values_rf\n",
        "\n",
        "df[\"remarks_rf\"] = \"\"\n",
        "df[\"remarks_rf\"] = df[\"remarks_rf\"].astype(str)\n",
        "df[\"remarks_rf\"] = df[\"predicted_attention_values_rf\"].apply(lambda x: analyze_sentiment(x))\n"
      ],
      "metadata": {
        "id": "MPJBVmklTFFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: do for predicted_attention_values_xgb\n",
        "\n",
        "df[\"remarks_xgb\"] = \"\"\n",
        "df[\"remarks_xgb\"] = df[\"remarks_xgb\"].astype(str)\n",
        "df[\"remarks_xgb\"] = df[\"predicted_attention_values_xgb\"].apply(lambda x: analyze_sentiment(x))\n"
      ],
      "metadata": {
        "id": "kpwQPmXHTgYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: do for predicted_attention_values_dt\n",
        "\n",
        "df[\"remarks_dt\"] = \"\"\n",
        "df[\"remarks_dt\"] = df[\"remarks_dt\"].astype(str)\n",
        "df[\"remarks_dt\"] = df[\"predicted_attention_values_dt\"].apply(lambda x: analyze_sentiment(x))\n"
      ],
      "metadata": {
        "id": "sXwhjtjnTwrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: vizualize it\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='remarks', data=df)\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment Category')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kJKUd-PLT1By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: vizualize it\n",
        "\n",
        "# Count the occurrences of each sentiment category\n",
        "sentiment_counts = df['remarks'].value_counts()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment Category')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vN9GezqCTlT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: vizualize it\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='remarks', data=df)\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment Category')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YD4UKTJ7TVkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: vizualize the above code\n",
        "\n",
        "# Calculate the count of each sentiment category\n",
        "sentiment_counts = df['remarks'].value_counts()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment Category')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9UwtKjuDSxul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=df.index, y=\"predicted_attention_values\", hue=\"remarks\", data=df)\n",
        "plt.title('Sentiment Distribution - Scatter Plot')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Predicted Attention Values')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ybb39eElTDO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=pd.read_csv(\"test_data.csv\")"
      ],
      "metadata": {
        "id": "UhSdmc-wUc9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "EGDOXgsKUt3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: predict the same sentiment analysis for testing dataset which we have done for training dataset\n",
        "\n",
        "df2[\"remarks\"] = \"\"\n",
        "df2[\"remarks\"] = df2[\"remarks\"].astype(str)\n",
        "df2[\"remarks\"] = df2[\"predicted_attention_values\"].apply(lambda x: analyze_sentiment(x))\n",
        "\n",
        "df2[\"remarks_rf\"] = \"\"\n",
        "df2[\"remarks_rf\"] = df2[\"remarks_rf\"].astype(str)\n",
        "df2[\"remarks_rf\"] = df2[\"predicted_attention_values_rf\"].apply(lambda x: analyze_sentiment(x))\n",
        "\n",
        "\n",
        "df2[\"remarks_xgb\"] = \"\"\n",
        "df2[\"remarks_xgb\"] = df2[\"remarks_xgb\"].astype(str)\n",
        "df2[\"remarks_xgb\"] = df2[\"predicted_attention_values_xgb\"].apply(lambda x: analyze_sentiment(x))\n",
        "\n",
        "\n",
        "df2[\"remarks_dt\"] = \"\"\n",
        "df2[\"remarks_dt\"] = df2[\"remarks_dt\"].astype(str)\n",
        "df2[\"remarks_dt\"] = df2[\"predicted_attention_values_dt\"].apply(lambda x: analyze_sentiment(x))\n",
        "\n"
      ],
      "metadata": {
        "id": "auaZkEjoVI0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=df2.index, y=\"predicted_attention_values\", hue=\"remarks\", data=df2)\n",
        "plt.title('Sentiment Distribution - Scatter Plot')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Predicted Attention Values')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qgGrPDGlVaRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: compare the above two scatterplots as titled judgement on test data and train data\n",
        "\n",
        "print(\"Based on the scatterplots, the model's performance on the test data appears to be similar to its performance on the training data.\")\n",
        "print(\"Both datasets show a similar distribution of predicted attention values across different sentiment categories.\")\n",
        "print(\"This suggests that the model generalizes well to unseen data.\")\n",
        "print(\"However, a more detailed analysis, such as comparing specific metrics like accuracy or F1-score, would provide a more conclusive judgement.\")\n"
      ],
      "metadata": {
        "id": "qK7uGi_kV2ST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}